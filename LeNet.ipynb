{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f92458-7337-4b09-bf50-21f736eb616d",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d4c45a-3fc0-4f22-8816-accaf686c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bbde8-cc28-4072-91a1-ab1d4c9dd966",
   "metadata": {},
   "source": [
    "## Working on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3101a66-5fc6-413b-b1cf-900faddb8db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "\n",
    "# Normalizing the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "\n",
    "x_train = x_train.reshape([-1, 28, 28, 1])\n",
    "x_test = x_test.reshape([-1, 28, 28, 1])\n",
    "\n",
    "\n",
    "# Converting image to 32x32\n",
    "x_train = np.pad(x_train, ((0, 0), (2, 2), (2, 2), (0, 0)), mode=\"constant\").astype(np.float32)\n",
    "x_test = np.pad(x_test, ((0, 0), (2, 2), (2, 2), (0, 0)), mode=\"constant\").astype(np.float32)\n",
    "\n",
    "# One_hot encodng of the labels \n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390aa588-bc4a-4d3c-8897-74ffa2f07414",
   "metadata": {},
   "source": [
    "## Asserting and Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d76f24f-5262-4cd3-8f63-95097b48e031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data for train images: 60000\n",
      "Size of data for test images: 10000\n",
      "Image shape: (32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28cdea7d390>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Shapes\n",
    "print(\"Size of data for train images:\", len(x_train))\n",
    "print(\"Size of data for test images:\", len(x_test))\n",
    "\n",
    "# Visualizing data\n",
    "sample = x_train[5]\n",
    "print(\"Image shape:\", sample.shape)\n",
    "plt.imshow(sample, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f097b2-060c-408c-8672-8c071def07d7",
   "metadata": {},
   "source": [
    "## Defining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121e8d50-503f-4069-832e-0ae5e4fb4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "keep_prob = 0.25\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0dbd83-7bda-4f63-873a-31e1efa931d3",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b7db45-6bcd-4589-bb76-5d3a15e85091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(x, y):\n",
    "    batches_data = []\n",
    "    for batch in range(0, len(x), batch_size):\n",
    "        batches_data.append((x[batch:batch+batch_size], y[batch:batch+batch_size]))\n",
    "    return batches_data\n",
    "\n",
    "class MyModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        # Weights\n",
    "        self.conv1 = tf.Variable(tf.random.normal([5, 5, 1, 6]), name=\"conv1\")\n",
    "        self.conv2 = tf.Variable(tf.random.normal([5, 5, 6, 16]), name=\"conv2\")\n",
    "        self.fc1 = tf.Variable(tf.random.normal([400, 120]), name=\"fc1\")\n",
    "        self.fc2 = tf.Variable(tf.random.normal([120, 84]), name=\"fc2\")\n",
    "        self.fc3 = tf.Variable(tf.random.normal([84, 10]), name=\"fc3\")\n",
    "        \n",
    "        # Bias\n",
    "        self.bias1 = tf.Variable(tf.random.normal([6]), name=\"bias1\")\n",
    "        self.bias2 = tf.Variable(tf.random.normal([16]), name=\"bias2\")\n",
    "        self.bias4 = tf.Variable(tf.random.normal([120]), name=\"bias4\")\n",
    "        self.bias5 = tf.Variable(tf.random.normal([84]), name=\"bias5\")\n",
    "        self.bias6 = tf.Variable(tf.random.normal([10]), name=\"bias6\")\n",
    "\n",
    "    \n",
    "    def __call__(self, x, keep_prob):\n",
    "        # Layer 1: Convolutional Layer 1 - Input is 32x32x1 \n",
    "        x = tf.nn.conv2d(x, self.conv1, strides=[1, 1, 1, 1], padding=\"VALID\") # Input: 32x32x1 Output: 28x28x6 \n",
    "        x = tf.nn.bias_add(x, self.bias1)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\") # Input: 28x28x6  Output: 14x14x6\n",
    "\n",
    "        # Layer 2: Convolutional Layer 2 - Input is 14x14x6\n",
    "        x = tf.nn.conv2d(x, self.conv2, strides=[1, 1, 1, 1], padding=\"VALID\") # Input: 14x14x6 Output: 10x10x16 \n",
    "        x = tf.nn.bias_add(x, self.bias2)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\") # Input: 10x10x16  Output: 5x5x16\n",
    "\n",
    "        # Layer 3: Flatten Layer - Input is 5x5x16\n",
    "        #x = Flatten()(x)\n",
    "        x = tf.reshape(x, [-1, 5*5*16])\n",
    "\n",
    "        # Layer 4: Fully Connected Layer 1 - Input: 400 Output: 120\n",
    "        x = tf.matmul(x, self.fc1)\n",
    "        x = tf.nn.bias_add(x, self.bias4)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Layer 5: Fully Connected Layer 2 - Input: 120 Output: 84\n",
    "        x = tf.matmul(x, self.fc2)\n",
    "        x = tf.nn.bias_add(x, self.bias5)\n",
    "        x = tf.nn.relu(x)\n",
    "        #x = tf.nn.dropout(x, rate=1 - keep_prob)\n",
    "\n",
    "        # Layer 6: Fully Connected Layer 3 - Input: 120 Output: 10\n",
    "        x = tf.matmul(x, self.fc3)\n",
    "        output = tf.nn.bias_add(x, self.bias6)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043b09c-738d-40c7-bf3c-244687a1d160",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3636a67b-4ed8-4ac3-a32f-19a2f778a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(labels, y):\n",
    "    #epsilon = 1e-10\n",
    "    #cross_entropy = -tf.reduce_sum(labels * tf.math.log(y + epsilon))\n",
    "    loss_avg = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=labels))\n",
    "    return loss_avg\n",
    "\n",
    "def optimization(x, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, keep_prob)\n",
    "        loss = compute_loss(labels, logits)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def compute_accuracy(labels, logits):\n",
    "    correct_prediction = tf.equal(tf.argmax(labels, 1), tf.argmax(logits, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e27da5-ccc4-4a14-852d-3e390f165ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ...\n",
      "Batch no: 50\n",
      "Validation loss: 7212.2646\n",
      "Validation accuracy: 0.1953125\n",
      "Epoch: 1 ...\n",
      "Batch no: 100\n",
      "Validation loss: 3929.0781\n",
      "Validation accuracy: 0.390625\n",
      "Epoch: 1 ...\n",
      "Batch no: 150\n",
      "Validation loss: 2201.0488\n",
      "Validation accuracy: 0.546875\n",
      "Epoch: 1 ...\n",
      "Batch no: 200\n",
      "Validation loss: 1560.3729\n",
      "Validation accuracy: 0.640625\n",
      "Epoch: 1 ...\n",
      "Batch no: 250\n",
      "Validation loss: 1436.1372\n",
      "Validation accuracy: 0.65625\n",
      "Epoch: 1 ...\n",
      "Batch no: 300\n",
      "Validation loss: 894.0558\n",
      "Validation accuracy: 0.7578125\n",
      "Epoch: 1 ...\n",
      "Batch no: 350\n",
      "Validation loss: 862.1345\n",
      "Validation accuracy: 0.7734375\n",
      "Epoch: 1 ...\n",
      "Batch no: 400\n",
      "Validation loss: 1163.8776\n",
      "Validation accuracy: 0.734375\n",
      "Epoch: 1 ...\n",
      "Batch no: 450\n",
      "Validation loss: 1058.2859\n",
      "Validation accuracy: 0.703125\n",
      "Epoch: 2 ...\n",
      "Batch no: 500\n",
      "Validation loss: 794.21906\n",
      "Validation accuracy: 0.75\n",
      "Epoch: 2 ...\n",
      "Batch no: 550\n",
      "Validation loss: 397.25092\n",
      "Validation accuracy: 0.8515625\n",
      "Epoch: 2 ...\n",
      "Batch no: 600\n",
      "Validation loss: 392.64594\n",
      "Validation accuracy: 0.890625\n",
      "Epoch: 2 ...\n",
      "Batch no: 650\n",
      "Validation loss: 699.3313\n",
      "Validation accuracy: 0.796875\n",
      "Epoch: 2 ...\n",
      "Batch no: 700\n",
      "Validation loss: 579.04565\n",
      "Validation accuracy: 0.8203125\n",
      "Epoch: 2 ...\n",
      "Batch no: 750\n",
      "Validation loss: 358.84344\n",
      "Validation accuracy: 0.8828125\n",
      "Epoch: 2 ...\n",
      "Batch no: 800\n",
      "Validation loss: 467.00143\n",
      "Validation accuracy: 0.859375\n",
      "Epoch: 2 ...\n",
      "Batch no: 850\n",
      "Validation loss: 563.7138\n",
      "Validation accuracy: 0.890625\n",
      "Epoch: 2 ...\n",
      "Batch no: 900\n",
      "Validation loss: 557.7622\n",
      "Validation accuracy: 0.84375\n",
      "Epoch: 3 ...\n",
      "Batch no: 950\n",
      "Validation loss: 469.7356\n",
      "Validation accuracy: 0.8515625\n",
      "Epoch: 3 ...\n",
      "Batch no: 1000\n",
      "Validation loss: 307.64978\n",
      "Validation accuracy: 0.8671875\n",
      "Epoch: 3 ...\n",
      "Batch no: 1050\n",
      "Validation loss: 153.17496\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 3 ...\n",
      "Batch no: 1100\n",
      "Validation loss: 240.67271\n",
      "Validation accuracy: 0.8828125\n",
      "Epoch: 3 ...\n",
      "Batch no: 1150\n",
      "Validation loss: 383.62164\n",
      "Validation accuracy: 0.8515625\n",
      "Epoch: 3 ...\n",
      "Batch no: 1200\n",
      "Validation loss: 218.04567\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 3 ...\n",
      "Batch no: 1250\n",
      "Validation loss: 262.96844\n",
      "Validation accuracy: 0.890625\n",
      "Epoch: 3 ...\n",
      "Batch no: 1300\n",
      "Validation loss: 264.71033\n",
      "Validation accuracy: 0.90625\n",
      "Epoch: 3 ...\n",
      "Batch no: 1350\n",
      "Validation loss: 232.76755\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 3 ...\n",
      "Batch no: 1400\n",
      "Validation loss: 212.65323\n",
      "Validation accuracy: 0.90625\n",
      "Epoch: 4 ...\n",
      "Batch no: 1450\n",
      "Validation loss: 214.64842\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 4 ...\n",
      "Batch no: 1500\n",
      "Validation loss: 153.04387\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 4 ...\n",
      "Batch no: 1550\n",
      "Validation loss: 429.2989\n",
      "Validation accuracy: 0.8984375\n",
      "Epoch: 4 ...\n",
      "Batch no: 1600\n",
      "Validation loss: 178.0132\n",
      "Validation accuracy: 0.90625\n",
      "Epoch: 4 ...\n",
      "Batch no: 1650\n",
      "Validation loss: 218.2316\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 4 ...\n",
      "Batch no: 1700\n",
      "Validation loss: 107.0628\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 4 ...\n",
      "Batch no: 1750\n",
      "Validation loss: 147.94731\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 4 ...\n",
      "Batch no: 1800\n",
      "Validation loss: 108.791916\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 4 ...\n",
      "Batch no: 1850\n",
      "Validation loss: 286.4939\n",
      "Validation accuracy: 0.8984375\n",
      "Epoch: 5 ...\n",
      "Batch no: 1900\n",
      "Validation loss: 113.52376\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 5 ...\n",
      "Batch no: 1950\n",
      "Validation loss: 165.41394\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 5 ...\n",
      "Batch no: 2000\n",
      "Validation loss: 107.80307\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 5 ...\n",
      "Batch no: 2050\n",
      "Validation loss: 228.7201\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 5 ...\n",
      "Batch no: 2100\n",
      "Validation loss: 137.62935\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 5 ...\n",
      "Batch no: 2150\n",
      "Validation loss: 241.92676\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 5 ...\n",
      "Batch no: 2200\n",
      "Validation loss: 158.83037\n",
      "Validation accuracy: 0.90625\n",
      "Epoch: 5 ...\n",
      "Batch no: 2250\n",
      "Validation loss: 128.2337\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 5 ...\n",
      "Batch no: 2300\n",
      "Validation loss: 136.7674\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 6 ...\n",
      "Batch no: 2350\n",
      "Validation loss: 99.69768\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 6 ...\n",
      "Batch no: 2400\n",
      "Validation loss: 136.40117\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 6 ...\n",
      "Batch no: 2450\n",
      "Validation loss: 117.947\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 6 ...\n",
      "Batch no: 2500\n",
      "Validation loss: 109.42914\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 6 ...\n",
      "Batch no: 2550\n",
      "Validation loss: 93.75607\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 6 ...\n",
      "Batch no: 2600\n",
      "Validation loss: 173.01495\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 6 ...\n",
      "Batch no: 2650\n",
      "Validation loss: 78.34424\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 6 ...\n",
      "Batch no: 2700\n",
      "Validation loss: 112.22243\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 6 ...\n",
      "Batch no: 2750\n",
      "Validation loss: 126.05756\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 6 ...\n",
      "Batch no: 2800\n",
      "Validation loss: 101.87805\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 7 ...\n",
      "Batch no: 2850\n",
      "Validation loss: 40.0521\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 7 ...\n",
      "Batch no: 2900\n",
      "Validation loss: 118.88684\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 7 ...\n",
      "Batch no: 2950\n",
      "Validation loss: 206.8494\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 7 ...\n",
      "Batch no: 3000\n",
      "Validation loss: 161.3476\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 7 ...\n",
      "Batch no: 3050\n",
      "Validation loss: 37.612907\n",
      "Validation accuracy: 0.96875\n",
      "Epoch: 7 ...\n",
      "Batch no: 3100\n",
      "Validation loss: 111.17048\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 7 ...\n",
      "Batch no: 3150\n",
      "Validation loss: 147.37056\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 7 ...\n",
      "Batch no: 3200\n",
      "Validation loss: 110.32955\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 7 ...\n",
      "Batch no: 3250\n",
      "Validation loss: 156.3774\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 8 ...\n",
      "Batch no: 3300\n",
      "Validation loss: 92.422386\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 8 ...\n",
      "Batch no: 3350\n",
      "Validation loss: 76.655655\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 8 ...\n",
      "Batch no: 3400\n",
      "Validation loss: 145.73312\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 8 ...\n",
      "Batch no: 3450\n",
      "Validation loss: 56.225292\n",
      "Validation accuracy: 0.96875\n",
      "Epoch: 8 ...\n",
      "Batch no: 3500\n",
      "Validation loss: 74.16418\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 8 ...\n",
      "Batch no: 3550\n",
      "Validation loss: 85.374725\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 8 ...\n",
      "Batch no: 3600\n",
      "Validation loss: 74.337234\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 8 ...\n",
      "Batch no: 3650\n",
      "Validation loss: 85.62557\n",
      "Validation accuracy: 0.96875\n",
      "Epoch: 8 ...\n",
      "Batch no: 3700\n",
      "Validation loss: 72.92476\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 8 ...\n",
      "Batch no: 3750\n",
      "Validation loss: 143.80017\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 9 ...\n",
      "Batch no: 3800\n",
      "Validation loss: 119.16793\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 9 ...\n",
      "Batch no: 3850\n",
      "Validation loss: 51.55163\n",
      "Validation accuracy: 0.96875\n",
      "Epoch: 9 ...\n",
      "Batch no: 3900\n",
      "Validation loss: 80.565796\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 9 ...\n",
      "Batch no: 3950\n",
      "Validation loss: 16.834284\n",
      "Validation accuracy: 0.9765625\n",
      "Epoch: 9 ...\n",
      "Batch no: 4000\n",
      "Validation loss: 125.0159\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 9 ...\n",
      "Batch no: 4050\n",
      "Validation loss: 56.401287\n",
      "Validation accuracy: 0.96875\n",
      "Epoch: 9 ...\n",
      "Batch no: 4100\n",
      "Validation loss: 44.339268\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 9 ...\n",
      "Batch no: 4150\n",
      "Validation loss: 5.6137886\n",
      "Validation accuracy: 0.9765625\n",
      "Epoch: 9 ...\n",
      "Batch no: 4200\n",
      "Validation loss: 111.84015\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 10 ...\n",
      "Batch no: 4250\n",
      "Validation loss: 26.572226\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 10 ...\n",
      "Batch no: 4300\n",
      "Validation loss: 65.85771\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 10 ...\n",
      "Batch no: 4350\n",
      "Validation loss: 106.333405\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 10 ...\n",
      "Batch no: 4400\n",
      "Validation loss: 53.084667\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 10 ...\n",
      "Batch no: 4450\n",
      "Validation loss: 41.430595\n",
      "Validation accuracy: 0.9765625\n",
      "Epoch: 10 ...\n",
      "Batch no: 4500\n",
      "Validation loss: 65.29674\n",
      "Validation accuracy: 0.96875\n",
      "Epoch: 10 ...\n",
      "Batch no: 4550\n",
      "Validation loss: 39.534313\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 10 ...\n",
      "Batch no: 4600\n",
      "Validation loss: 100.00217\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 10 ...\n",
      "Batch no: 4650\n",
      "Validation loss: 71.02953\n",
      "Validation accuracy: 0.96875\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "batch_no = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batches_x, batches_y in batches(x_train, y_train):\n",
    "        loss = optimization(batches_x, batches_y)\n",
    "        logits = model(batches_x, keep_prob=1.0)\n",
    "        accuracy = compute_accuracy(batches_y, logits)\n",
    "        if batch_no % 50 == 0:\n",
    "            print(\"Epoch:\", epoch + 1, \"...\")\n",
    "            print(\"Batch no:\", batch_no)\n",
    "            print(\"Validation loss:\", loss.numpy())\n",
    "            print(\"Validation accuracy:\", accuracy.numpy())\n",
    "        batch_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db578067-8bb3-4c1d-aab3-c2563f88e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"./model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5196ab35-d0fb-4d41-87e6-9352ec8e8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(x_test, keep_prob=1)\n",
    "accuracy = compute_accuracy(y_test, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68f94cb-1f42-4009-a127-4902995ab53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_accuracy: 0.9509\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_accuracy:\", accuracy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478fc4d-ff66-4d26-9476-0a15f378a632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
