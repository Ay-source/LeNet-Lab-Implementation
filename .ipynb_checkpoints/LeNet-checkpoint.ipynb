{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f92458-7337-4b09-bf50-21f736eb616d",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d4c45a-3fc0-4f22-8816-accaf686c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bbde8-cc28-4072-91a1-ab1d4c9dd966",
   "metadata": {},
   "source": [
    "## Working on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3101a66-5fc6-413b-b1cf-900faddb8db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = mnist\n",
    "\n",
    "# Normalizing the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "\n",
    "x_train = x_train.reshape([-1, 28, 28, 1])\n",
    "x_test = x_test.reshape([-1, 28, 28, 1])\n",
    "\n",
    "\n",
    "# Converting image to 32x32\n",
    "x_train = np.pad(x_train, ((0, 0), (2, 2), (2, 2), (0, 0)), mode=\"constant\").astype(np.float32)\n",
    "x_test = np.pad(x_test, ((0, 0), (2, 2), (2, 2), (0, 0)), mode=\"constant\").astype(np.float32)\n",
    "\n",
    "# One_hot encodng of the labels \n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390aa588-bc4a-4d3c-8897-74ffa2f07414",
   "metadata": {},
   "source": [
    "## Asserting and Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d76f24f-5262-4cd3-8f63-95097b48e031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data for train images: 60000\n",
      "Size of data for test images: 10000\n",
      "Image shape: (32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c504c51720>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Shapes\n",
    "print(\"Size of data for train images:\", len(x_train))\n",
    "print(\"Size of data for test images:\", len(x_test))\n",
    "\n",
    "# Visualizing data\n",
    "sample = x_train[5]\n",
    "print(\"Image shape:\", sample.shape)\n",
    "plt.imshow(sample, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f097b2-060c-408c-8672-8c071def07d7",
   "metadata": {},
   "source": [
    "## Defining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "121e8d50-503f-4069-832e-0ae5e4fb4400",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "keep_prob = 0.25\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0dbd83-7bda-4f63-873a-31e1efa931d3",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27b7db45-6bcd-4589-bb76-5d3a15e85091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(x, y):\n",
    "    batches_data = []\n",
    "    for batch in range(0, len(x), batch_size):\n",
    "        batches_data.append((x[batch:batch+batch_size], y[batch:batch+batch_size]))\n",
    "    return batches_data\n",
    "\n",
    "class MyModel(tf.Module):\n",
    "    def __init__(self):\n",
    "        # Weights\n",
    "        self.conv1 = tf.Variable(tf.random.normal([5, 5, 1, 6]), name=\"conv1\")\n",
    "        self.conv2 = tf.Variable(tf.random.normal([5, 5, 6, 16]), name=\"conv2\")\n",
    "        self.fc1 = tf.Variable(tf.random.normal([400, 120]), name=\"fc1\")\n",
    "        self.fc2 = tf.Variable(tf.random.normal([120, 84]), name=\"fc2\")\n",
    "        self.fc3 = tf.Variable(tf.random.normal([84, 10]), name=\"fc3\")\n",
    "        \n",
    "        # Bias\n",
    "        self.bias1 = tf.Variable(tf.random.normal([6]), name=\"bias1\")\n",
    "        self.bias2 = tf.Variable(tf.random.normal([16]), name=\"bias2\")\n",
    "        self.bias4 = tf.Variable(tf.random.normal([120]), name=\"bias4\")\n",
    "        self.bias5 = tf.Variable(tf.random.normal([84]), name=\"bias5\")\n",
    "        self.bias6 = tf.Variable(tf.random.normal([10]), name=\"bias6\")\n",
    "\n",
    "    \n",
    "    def __call__(self, x, keep_prob):\n",
    "        # Layer 1: Convolutional Layer 1 - Input is 32x32x1 \n",
    "        x = tf.nn.conv2d(x, self.conv1, strides=[1, 1, 1, 1], padding=\"VALID\") # Input: 32x32x1 Output: 28x28x6 \n",
    "        x = tf.nn.bias_add(x, self.bias1)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\") # Input: 28x28x6  Output: 14x14x6\n",
    "\n",
    "        # Layer 2: Convolutional Layer 2 - Input is 14x14x6\n",
    "        x = tf.nn.conv2d(x, self.conv2, strides=[1, 1, 1, 1], padding=\"VALID\") # Input: 14x14x6 Output: 10x10x16 \n",
    "        x = tf.nn.bias_add(x, self.bias2)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\") # Input: 10x10x16  Output: 5x5x16\n",
    "\n",
    "        # Layer 3: Flatten Layer - Input is 5x5x16\n",
    "        #x = Flatten()(x)\n",
    "        x = tf.reshape(x, [-1, 5*5*16])\n",
    "\n",
    "        # Layer 4: Fully Connected Layer 1 - Input: 400 Output: 120\n",
    "        x = tf.matmul(x, self.fc1)\n",
    "        x = tf.nn.bias_add(x, self.bias4)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # Layer 5: Fully Connected Layer 2 - Input: 120 Output: 84\n",
    "        x = tf.matmul(x, self.fc2)\n",
    "        x = tf.nn.bias_add(x, self.bias5)\n",
    "        x = tf.nn.relu(x)\n",
    "        #x = tf.nn.dropout(x, rate=1 - keep_prob)\n",
    "\n",
    "        # Layer 6: Fully Connected Layer 3 - Input: 120 Output: 10\n",
    "        x = tf.matmul(x, self.fc3)\n",
    "        output = tf.nn.bias_add(x, self.bias6)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043b09c-738d-40c7-bf3c-244687a1d160",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3636a67b-4ed8-4ac3-a32f-19a2f778a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(labels, y):\n",
    "    #epsilon = 1e-10\n",
    "    #cross_entropy = -tf.reduce_sum(labels * tf.math.log(y + epsilon))\n",
    "    loss_avg = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=labels))\n",
    "    return loss_avg\n",
    "\n",
    "def optimization(x, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, keep_prob)\n",
    "        loss = compute_loss(labels, logits)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def compute_accuracy(labels, logits):\n",
    "    correct_prediction = tf.equal(tf.argmax(labels, 1), tf.argmax(logits, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e27da5-ccc4-4a14-852d-3e390f165ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ...\n",
      "Batch no: 50\n",
      "Validation loss: 7638.5757\n",
      "Validation accuracy: 0.265625\n",
      "Epoch: 1 ...\n",
      "Batch no: 100\n",
      "Validation loss: 2221.9106\n",
      "Validation accuracy: 0.5234375\n",
      "Epoch: 1 ...\n",
      "Batch no: 150\n",
      "Validation loss: 2031.072\n",
      "Validation accuracy: 0.6328125\n",
      "Epoch: 1 ...\n",
      "Batch no: 200\n",
      "Validation loss: 711.3206\n",
      "Validation accuracy: 0.71875\n",
      "Epoch: 1 ...\n",
      "Batch no: 250\n",
      "Validation loss: 1092.631\n",
      "Validation accuracy: 0.6875\n",
      "Epoch: 1 ...\n",
      "Batch no: 300\n",
      "Validation loss: 1190.7021\n",
      "Validation accuracy: 0.6953125\n",
      "Epoch: 1 ...\n",
      "Batch no: 350\n",
      "Validation loss: 723.6783\n",
      "Validation accuracy: 0.796875\n",
      "Epoch: 1 ...\n",
      "Batch no: 400\n",
      "Validation loss: 768.4487\n",
      "Validation accuracy: 0.7578125\n",
      "Epoch: 1 ...\n",
      "Batch no: 450\n",
      "Validation loss: 650.02496\n",
      "Validation accuracy: 0.8046875\n",
      "Epoch: 2 ...\n",
      "Batch no: 500\n",
      "Validation loss: 532.91003\n",
      "Validation accuracy: 0.84375\n",
      "Epoch: 2 ...\n",
      "Batch no: 550\n",
      "Validation loss: 408.20453\n",
      "Validation accuracy: 0.8125\n",
      "Epoch: 2 ...\n",
      "Batch no: 600\n",
      "Validation loss: 393.3296\n",
      "Validation accuracy: 0.8359375\n",
      "Epoch: 2 ...\n",
      "Batch no: 650\n",
      "Validation loss: 365.85242\n",
      "Validation accuracy: 0.8046875\n",
      "Epoch: 2 ...\n",
      "Batch no: 700\n",
      "Validation loss: 252.88278\n",
      "Validation accuracy: 0.859375\n",
      "Epoch: 2 ...\n",
      "Batch no: 750\n",
      "Validation loss: 720.1926\n",
      "Validation accuracy: 0.8046875\n",
      "Epoch: 2 ...\n",
      "Batch no: 800\n",
      "Validation loss: 463.5087\n",
      "Validation accuracy: 0.84375\n",
      "Epoch: 2 ...\n",
      "Batch no: 850\n",
      "Validation loss: 331.92014\n",
      "Validation accuracy: 0.8828125\n",
      "Epoch: 2 ...\n",
      "Batch no: 900\n",
      "Validation loss: 528.66565\n",
      "Validation accuracy: 0.84375\n",
      "Epoch: 3 ...\n",
      "Batch no: 950\n",
      "Validation loss: 442.6001\n",
      "Validation accuracy: 0.859375\n",
      "Epoch: 3 ...\n",
      "Batch no: 1000\n",
      "Validation loss: 317.59015\n",
      "Validation accuracy: 0.8671875\n",
      "Epoch: 3 ...\n",
      "Batch no: 1050\n",
      "Validation loss: 396.65137\n",
      "Validation accuracy: 0.859375\n",
      "Epoch: 3 ...\n",
      "Batch no: 1100\n",
      "Validation loss: 212.71207\n",
      "Validation accuracy: 0.90625\n",
      "Epoch: 3 ...\n",
      "Batch no: 1150\n",
      "Validation loss: 391.17297\n",
      "Validation accuracy: 0.859375\n",
      "Epoch: 3 ...\n",
      "Batch no: 1200\n",
      "Validation loss: 199.37688\n",
      "Validation accuracy: 0.8828125\n",
      "Epoch: 3 ...\n",
      "Batch no: 1250\n",
      "Validation loss: 455.40558\n",
      "Validation accuracy: 0.828125\n",
      "Epoch: 3 ...\n",
      "Batch no: 1300\n",
      "Validation loss: 294.7163\n",
      "Validation accuracy: 0.8828125\n",
      "Epoch: 3 ...\n",
      "Batch no: 1350\n",
      "Validation loss: 245.11697\n",
      "Validation accuracy: 0.890625\n",
      "Epoch: 3 ...\n",
      "Batch no: 1400\n",
      "Validation loss: 290.9652\n",
      "Validation accuracy: 0.90625\n",
      "Epoch: 4 ...\n",
      "Batch no: 1450\n",
      "Validation loss: 182.38263\n",
      "Validation accuracy: 0.8984375\n",
      "Epoch: 4 ...\n",
      "Batch no: 1500\n",
      "Validation loss: 317.55457\n",
      "Validation accuracy: 0.8671875\n",
      "Epoch: 4 ...\n",
      "Batch no: 1550\n",
      "Validation loss: 80.1025\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 4 ...\n",
      "Batch no: 1600\n",
      "Validation loss: 250.1051\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 4 ...\n",
      "Batch no: 1650\n",
      "Validation loss: 162.9302\n",
      "Validation accuracy: 0.8671875\n",
      "Epoch: 4 ...\n",
      "Batch no: 1700\n",
      "Validation loss: 218.42654\n",
      "Validation accuracy: 0.90625\n",
      "Epoch: 4 ...\n",
      "Batch no: 1750\n",
      "Validation loss: 182.94806\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 4 ...\n",
      "Batch no: 1800\n",
      "Validation loss: 186.9548\n",
      "Validation accuracy: 0.90625\n",
      "Epoch: 4 ...\n",
      "Batch no: 1850\n",
      "Validation loss: 249.87613\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 5 ...\n",
      "Batch no: 1900\n",
      "Validation loss: 179.19794\n",
      "Validation accuracy: 0.8984375\n",
      "Epoch: 5 ...\n",
      "Batch no: 1950\n",
      "Validation loss: 259.01154\n",
      "Validation accuracy: 0.8828125\n",
      "Epoch: 5 ...\n",
      "Batch no: 2000\n",
      "Validation loss: 96.40657\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 5 ...\n",
      "Batch no: 2050\n",
      "Validation loss: 425.2328\n",
      "Validation accuracy: 0.875\n",
      "Epoch: 5 ...\n",
      "Batch no: 2100\n",
      "Validation loss: 47.368378\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 5 ...\n",
      "Batch no: 2150\n",
      "Validation loss: 111.13137\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 5 ...\n",
      "Batch no: 2200\n",
      "Validation loss: 193.6236\n",
      "Validation accuracy: 0.890625\n",
      "Epoch: 5 ...\n",
      "Batch no: 2250\n",
      "Validation loss: 207.99588\n",
      "Validation accuracy: 0.8671875\n",
      "Epoch: 5 ...\n",
      "Batch no: 2300\n",
      "Validation loss: 132.93138\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 6 ...\n",
      "Batch no: 2350\n",
      "Validation loss: 110.3625\n",
      "Validation accuracy: 0.8984375\n",
      "Epoch: 6 ...\n",
      "Batch no: 2400\n",
      "Validation loss: 94.671616\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 6 ...\n",
      "Batch no: 2450\n",
      "Validation loss: 211.24011\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 6 ...\n",
      "Batch no: 2500\n",
      "Validation loss: 51.992657\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 6 ...\n",
      "Batch no: 2550\n",
      "Validation loss: 106.02113\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 6 ...\n",
      "Batch no: 2600\n",
      "Validation loss: 75.730576\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 6 ...\n",
      "Batch no: 2650\n",
      "Validation loss: 58.609524\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 6 ...\n",
      "Batch no: 2700\n",
      "Validation loss: 54.925842\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 6 ...\n",
      "Batch no: 2750\n",
      "Validation loss: 56.114143\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 6 ...\n",
      "Batch no: 2800\n",
      "Validation loss: 143.6528\n",
      "Validation accuracy: 0.8984375\n",
      "Epoch: 7 ...\n",
      "Batch no: 2850\n",
      "Validation loss: 68.51956\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 7 ...\n",
      "Batch no: 2900\n",
      "Validation loss: 52.86163\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 7 ...\n",
      "Batch no: 2950\n",
      "Validation loss: 49.995018\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 7 ...\n",
      "Batch no: 3000\n",
      "Validation loss: 141.59767\n",
      "Validation accuracy: 0.90625\n",
      "Epoch: 7 ...\n",
      "Batch no: 3050\n",
      "Validation loss: 70.84668\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 7 ...\n",
      "Batch no: 3100\n",
      "Validation loss: 79.996124\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 7 ...\n",
      "Batch no: 3150\n",
      "Validation loss: 168.33337\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 7 ...\n",
      "Batch no: 3200\n",
      "Validation loss: 114.72807\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 7 ...\n",
      "Batch no: 3250\n",
      "Validation loss: 64.754585\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 8 ...\n",
      "Batch no: 3300\n",
      "Validation loss: 118.80545\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 8 ...\n",
      "Batch no: 3350\n",
      "Validation loss: 103.15842\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 8 ...\n",
      "Batch no: 3400\n",
      "Validation loss: 87.22535\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 8 ...\n",
      "Batch no: 3450\n",
      "Validation loss: 63.728786\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 8 ...\n",
      "Batch no: 3500\n",
      "Validation loss: 81.55266\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 8 ...\n",
      "Batch no: 3550\n",
      "Validation loss: 206.86606\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 8 ...\n",
      "Batch no: 3600\n",
      "Validation loss: 166.20593\n",
      "Validation accuracy: 0.921875\n",
      "Epoch: 8 ...\n",
      "Batch no: 3650\n",
      "Validation loss: 139.98466\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 8 ...\n",
      "Batch no: 3700\n",
      "Validation loss: 39.29418\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 8 ...\n",
      "Batch no: 3750\n",
      "Validation loss: 51.013718\n",
      "Validation accuracy: 0.9453125\n",
      "Epoch: 9 ...\n",
      "Batch no: 3800\n",
      "Validation loss: 61.02121\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 9 ...\n",
      "Batch no: 3850\n",
      "Validation loss: 57.140835\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 9 ...\n",
      "Batch no: 3900\n",
      "Validation loss: 71.35959\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 9 ...\n",
      "Batch no: 3950\n",
      "Validation loss: 112.8371\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 9 ...\n",
      "Batch no: 4000\n",
      "Validation loss: 107.2097\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 9 ...\n",
      "Batch no: 4050\n",
      "Validation loss: 94.29069\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 9 ...\n",
      "Batch no: 4100\n",
      "Validation loss: 66.36029\n",
      "Validation accuracy: 0.9296875\n",
      "Epoch: 9 ...\n",
      "Batch no: 4150\n",
      "Validation loss: 71.95256\n",
      "Validation accuracy: 0.96875\n",
      "Epoch: 9 ...\n",
      "Batch no: 4200\n",
      "Validation loss: 79.76009\n",
      "Validation accuracy: 0.9375\n",
      "Epoch: 10 ...\n",
      "Batch no: 4250\n",
      "Validation loss: 87.403564\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 10 ...\n",
      "Batch no: 4300\n",
      "Validation loss: 55.676582\n",
      "Validation accuracy: 0.9765625\n",
      "Epoch: 10 ...\n",
      "Batch no: 4350\n",
      "Validation loss: 24.08123\n",
      "Validation accuracy: 0.96875\n",
      "Epoch: 10 ...\n",
      "Batch no: 4400\n",
      "Validation loss: 115.93838\n",
      "Validation accuracy: 0.9140625\n",
      "Epoch: 10 ...\n",
      "Batch no: 4450\n",
      "Validation loss: 40.07301\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 10 ...\n",
      "Batch no: 4500\n",
      "Validation loss: 69.83414\n",
      "Validation accuracy: 0.953125\n",
      "Epoch: 10 ...\n",
      "Batch no: 4550\n",
      "Validation loss: 29.885239\n",
      "Validation accuracy: 0.9609375\n",
      "Epoch: 10 ...\n",
      "Batch no: 4600\n",
      "Validation loss: 2.6143456\n",
      "Validation accuracy: 0.9921875\n",
      "Epoch: 10 ...\n",
      "Batch no: 4650\n",
      "Validation loss: 11.65526\n",
      "Validation accuracy: 0.9765625\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "batch_no = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batches_x, batches_y in batches(x_train, y_train):\n",
    "        loss = optimization(batches_x, batches_y)\n",
    "        logits = model(batches_x, keep_prob=1.0)\n",
    "        accuracy = compute_accuracy(batches_y, logits)\n",
    "        if batch_no % 50 == 0:\n",
    "            print(\"Epoch:\", epoch + 1, \"...\")\n",
    "            print(\"Batch no:\", batch_no)\n",
    "            print(\"Validation loss:\", loss.numpy())\n",
    "            print(\"Validation accuracy:\", accuracy.numpy())\n",
    "        batch_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5196ab35-d0fb-4d41-87e6-9352ec8e8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(x_test, keep_prob=1)\n",
    "accuracy = compute_accuracy(y_test, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68f94cb-1f42-4009-a127-4902995ab53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_accuracy: 0.9392\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_accuracy:\", accuracy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478fc4d-ff66-4d26-9476-0a15f378a632",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
